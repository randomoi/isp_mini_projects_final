{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deba06f-15a7-48a4-89d0-bae6e3e26400",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34b9ef-39c4-4f41-936e-ceb64a1a2803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5fb63-2db1-40e6-9845-cde9fbc2cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# loading video\n",
    "# video_capture = cv2.VideoCapture('video/Traffic_Laramie_1.mp4')\n",
    "video_capture = cv2.VideoCapture('video/bicycle.mp4')\n",
    "# video_capture = cv2.VideoCapture('video/part1_2cars.mp4')\n",
    "# video_capture = cv2.VideoCapture('video/part2_2cars.mp4')\n",
    "# video_capture = cv2.VideoCapture('video/part3_2cars.mp4')\n",
    "\n",
    "# verify if opened succesfully\n",
    "if not video_capture.isOpened():\n",
    "    # print error message\n",
    "    print(\"Sorry, video couldn't be open video.\")\n",
    "    exit()\n",
    "else:\n",
    "    # print success message\n",
    "    print(\"Video opened successfully!\")\n",
    "    \n",
    "def get_video_capture(video_path):\n",
    "    return cv2.VideoCapture(video_path)\n",
    "\n",
    "# Configuration\n",
    "ROI_POINTS = np.array([[(300, 500), (350, 350), (400, 100), (400, 100), (400, 200), (500, 300)]], dtype=np.int32)\n",
    "WIDTH_THRESHOLD = 60\n",
    "HEIGHT_THRESHOLD = 45\n",
    "CAR_TTL = 5  # The number of frames to wait before removing a car from tracking\n",
    "\n",
    "def create_background_model():\n",
    "    return cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "def apply_morphology(mask):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "def is_new_car(x, y, w, h, tracked_cars):\n",
    "    for car in tracked_cars:\n",
    "        last_x, last_y, last_w, last_h, ttl = car\n",
    "        if abs(x - last_x) < w and abs(y - last_y) < h and abs(w - last_w) < 20 and abs(h - last_h) < 20:\n",
    "            car[4] = CAR_TTL  # Reset the TTL\n",
    "            return False\n",
    "    tracked_cars.append([x, y, w, h, CAR_TTL])\n",
    "    return True\n",
    "\n",
    "def detect_cars(frame, roi, backSub, tracked_cars):\n",
    "    fgMask = backSub.apply(frame)\n",
    "    fgMask = apply_morphology(fgMask)\n",
    "\n",
    "    mask = np.zeros_like(fgMask)\n",
    "    cv2.fillPoly(mask, roi, 255)\n",
    "    fgMask = cv2.bitwise_and(fgMask, mask)\n",
    "\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    car_count = 0\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > WIDTH_THRESHOLD and h > HEIGHT_THRESHOLD:\n",
    "            if is_new_car(x, y, w, h, tracked_cars):\n",
    "                car_count += 1\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Decrease TTL for all tracked cars and remove those that haven't been seen for a while\n",
    "    for car in tracked_cars:\n",
    "        car[4] -= 1  # Decrease TTL\n",
    "        if car[4] <= 0:\n",
    "            tracked_cars.remove(car)\n",
    "\n",
    "    return frame, car_count\n",
    "\n",
    "def get_video_duration_in_seconds(video_capture):\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = video_capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    duration_seconds = total_frames / fps\n",
    "    return duration_seconds\n",
    "\n",
    "\n",
    "class Car:\n",
    "    def __init__(self, bbox):\n",
    "        self.bbox = bbox\n",
    "        self.frames_since_last_update = 0\n",
    "\n",
    "    def get_center(self):\n",
    "        x, y, w, h = self.bbox\n",
    "        return x + w // 2, y + h // 2\n",
    "\n",
    "def main(video_path):\n",
    "    video_capture = get_video_capture(video_path)\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Could not open video\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "    tracked_cars = []\n",
    "    all_detected_cars = []  # List to keep track of all detected cars\n",
    "    ROI_POINTS = np.array([[(300, 500), (350, 350), (400, 100), (400, 100), (400, 200), (500, 300)]], dtype=np.int32)\n",
    "\n",
    "    # Warm-up phase\n",
    "    warmup_frames = 50\n",
    "    for _ in range(warmup_frames):\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            return\n",
    "        backSub.apply(frame)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        fgMask = backSub.apply(frame)\n",
    "        \n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Applying ROI mask to the fgMask\n",
    "        mask = np.zeros_like(fgMask)\n",
    "        cv2.fillPoly(mask, ROI_POINTS, 255)\n",
    "        fgMask = cv2.bitwise_and(fgMask, mask)\n",
    "        \n",
    "        contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        current_cars = []\n",
    "\n",
    "        MIN_AREA = 2500  # This is an arbitrary value, you might need to adjust\n",
    "        # WIDTH_THRESHOLD = 82\n",
    "        # HEIGHT_THRESHOLD = 45\n",
    "        WIDTH_THRESHOLD = 100\n",
    "        HEIGHT_THRESHOLD = 45\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if w > WIDTH_THRESHOLD and h > HEIGHT_THRESHOLD:\n",
    "                current_bbox = (x, y, w, h)\n",
    "                car_center = (x + w // 2, y + h // 2)\n",
    "                match_found = False\n",
    "\n",
    "                for car in tracked_cars:\n",
    "                    dist = np.linalg.norm(np.array(car.get_center()) - np.array(car_center))\n",
    "                    if dist < max(w, h):  # Using max of width and height as threshold\n",
    "                        car.bbox = current_bbox\n",
    "                        car.frames_since_last_update = 0\n",
    "                        match_found = True\n",
    "                        break\n",
    "\n",
    "                if not match_found:\n",
    "                    new_car = Car(current_bbox)\n",
    "                    current_cars.append(new_car)\n",
    "                    all_detected_cars.append(new_car)  # Add to all detected cars list\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "                \n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Add newly detected cars to the tracked cars list\n",
    "        tracked_cars.extend(current_cars)\n",
    "        \n",
    "        # Remove cars that have not been detected for a while\n",
    "        for car in tracked_cars:\n",
    "            car.frames_since_last_update += 1\n",
    "            if car.frames_since_last_update > 30:  # 30 can be adjusted based on video frame rate and car speed\n",
    "                tracked_cars.remove(car)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(30) == ord('q'):\n",
    "            break\n",
    "\n",
    "    unique_cars_count = len(all_detected_cars)\n",
    "    video_duration_seconds = get_video_duration_in_seconds(video_capture)\n",
    "    cars_per_second = unique_cars_count / video_duration_seconds\n",
    "    cars_per_minute = cars_per_second * 60  # Convert cars per second to cars per minute\n",
    "\n",
    "    print(f\"Total unique cars detected: {unique_cars_count}\")\n",
    "    print(f\"Cars detected per second: {cars_per_second:.2f}\")\n",
    "    print(f\"Cars detected per minute: {cars_per_minute:.2f}\")\n",
    "    \n",
    "\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main('video/Traffic_Laramie_1.mp4')\n",
    "    # main('video/Traffic_Laramie_2.mp4')\n",
    "    main('video/part1_2cars.mp4')\n",
    "    main('video/part2_2cars.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5ea96-31c9-4cd1-b107-f8532901159c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688b5df-0cd5-44dd-a0f9-e487694c17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e831e0-2e83-47b4-893e-c9d6aa0a7ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing video: video/Traffic_Laramie_1.mp4\n",
      "video/Traffic_Laramie_1.mp4 opened successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "  \n",
    "def get_video_capture(video_path):\n",
    "    return cv2.VideoCapture(video_path)\n",
    "\n",
    "# Configuration\n",
    "ROI_POINTS = np.array([[(300, 500), (350, 350), (400, 100), (400, 100), (400, 200), (500, 300)]], dtype=np.int32)\n",
    "WIDTH_THRESHOLD = 60\n",
    "HEIGHT_THRESHOLD = 45\n",
    "CAR_TTL = 5  # The number of frames to wait before removing a car from tracking\n",
    "\n",
    "def create_background_model():\n",
    "    return cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "def apply_morphology(mask):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "def is_new_car(x, y, w, h, tracked_cars):\n",
    "    for car in tracked_cars:\n",
    "        last_x, last_y, last_w, last_h, ttl = car\n",
    "        if abs(x - last_x) < w and abs(y - last_y) < h and abs(w - last_w) < 20 and abs(h - last_h) < 20:\n",
    "            car[4] = CAR_TTL  # Reset the TTL\n",
    "            return False\n",
    "    tracked_cars.append([x, y, w, h, CAR_TTL])\n",
    "    return True\n",
    "\n",
    "def detect_cars(frame, roi, backSub, tracked_cars):\n",
    "    fgMask = backSub.apply(frame)\n",
    "    fgMask = apply_morphology(fgMask)\n",
    "\n",
    "    mask = np.zeros_like(fgMask)\n",
    "    cv2.fillPoly(mask, roi, 255)\n",
    "    fgMask = cv2.bitwise_and(fgMask, mask)\n",
    "\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    car_count = 0\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > WIDTH_THRESHOLD and h > HEIGHT_THRESHOLD:\n",
    "            if is_new_car(x, y, w, h, tracked_cars):\n",
    "                car_count += 1\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Decrease TTL for all tracked cars and remove those that haven't been seen for a while\n",
    "    for car in tracked_cars:\n",
    "        car[4] -= 1  # Decrease TTL\n",
    "        if car[4] <= 0:\n",
    "            tracked_cars.remove(car)\n",
    "\n",
    "    return frame, car_count\n",
    "\n",
    "def get_video_duration_in_seconds(video_capture):\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = video_capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    duration_seconds = total_frames / fps\n",
    "    return duration_seconds\n",
    "\n",
    "\n",
    "class Car:\n",
    "    def __init__(self, bbox):\n",
    "        self.bbox = bbox\n",
    "        self.frames_since_last_update = 0\n",
    "\n",
    "    def get_center(self):\n",
    "        x, y, w, h = self.bbox\n",
    "        return x + w // 2, y + h // 2\n",
    "\n",
    "def main(video_path):\n",
    "    print(f\"Analyzing video: {video_path}\")  # <-- Added this line to indicate which video is being analyzed\n",
    "\n",
    "    video_capture = get_video_capture(video_path)\n",
    "#     if not video_capture.isOpened():\n",
    "#         print(\"Could not open video\")\n",
    "#         return\n",
    "    \n",
    "    # verify if opened succesfully\n",
    "    if not video_capture.isOpened():\n",
    "        # print error message\n",
    "        print(f\"Sorry, {video_path} couldn't be open video.\")\n",
    "        exit()\n",
    "    else:\n",
    "        # print success message\n",
    "        print(f\"{video_path} opened successfully!\")\n",
    "    \n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "    tracked_cars = []\n",
    "    all_detected_cars = []  # List to keep track of all detected cars\n",
    "    ROI_POINTS = np.array([[(300, 500), (350, 350), (400, 100), (400, 100), (400, 200), (500, 300)]], dtype=np.int32)\n",
    "\n",
    "    # Warm-up phase\n",
    "    warmup_frames = 50\n",
    "    for _ in range(warmup_frames):\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            return\n",
    "        backSub.apply(frame)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        fgMask = backSub.apply(frame)\n",
    "        \n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Applying ROI mask to the fgMask\n",
    "        mask = np.zeros_like(fgMask)\n",
    "        cv2.fillPoly(mask, ROI_POINTS, 255)\n",
    "        fgMask = cv2.bitwise_and(fgMask, mask)\n",
    "        \n",
    "        contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        current_cars = []\n",
    "\n",
    "        MIN_AREA = 2500  # This is an arbitrary value, you might need to adjust\n",
    "        # WIDTH_THRESHOLD = 82\n",
    "        # HEIGHT_THRESHOLD = 45\n",
    "        WIDTH_THRESHOLD = 100\n",
    "        HEIGHT_THRESHOLD = 45\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if w > WIDTH_THRESHOLD and h > HEIGHT_THRESHOLD:\n",
    "                current_bbox = (x, y, w, h)\n",
    "                car_center = (x + w // 2, y + h // 2)\n",
    "                match_found = False\n",
    "\n",
    "                for car in tracked_cars:\n",
    "                    dist = np.linalg.norm(np.array(car.get_center()) - np.array(car_center))\n",
    "                    if dist < max(w, h):  # Using max of width and height as threshold\n",
    "                        car.bbox = current_bbox\n",
    "                        car.frames_since_last_update = 0\n",
    "                        match_found = True\n",
    "                        break\n",
    "\n",
    "                if not match_found:\n",
    "                    new_car = Car(current_bbox)\n",
    "                    current_cars.append(new_car)\n",
    "                    all_detected_cars.append(new_car)  # Add to all detected cars list\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "                \n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Add newly detected cars to the tracked cars list\n",
    "        tracked_cars.extend(current_cars)\n",
    "        \n",
    "        # Remove cars that have not been detected for a while\n",
    "        for car in tracked_cars:\n",
    "            car.frames_since_last_update += 1\n",
    "            if car.frames_since_last_update > 30:  # 30 can be adjusted based on video frame rate and car speed\n",
    "                tracked_cars.remove(car)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(30) == ord('q'):\n",
    "            break\n",
    "\n",
    "    unique_cars_count = len(all_detected_cars)\n",
    "    video_duration_seconds = get_video_duration_in_seconds(video_capture)\n",
    "    cars_per_second = unique_cars_count / video_duration_seconds\n",
    "    cars_per_minute = cars_per_second * 60  # Convert cars per second to cars per minute\n",
    "  \n",
    "    return {\n",
    "        \"Video Name\": video_path,\n",
    "        \"Total Cars Detected\": unique_cars_count,\n",
    "        \"Cars/Minute\": cars_per_minute\n",
    "    }\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List to collect the data for all videos\n",
    "    data_list = []\n",
    "\n",
    "    video_paths = ['video/Traffic_Laramie_1.mp4', 'video/Traffic_Laramie_2.mp4'] \n",
    "    # video_paths = ['video/part1_2cars.mp4', 'video/part2_2cars.mp4'] \n",
    "\n",
    "    for video_path in video_paths:\n",
    "        result = main(video_path)\n",
    "        data_list.append(result)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # print the DataFrame:\n",
    "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f13816-829a-457d-bc50-5af6da7d2d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
