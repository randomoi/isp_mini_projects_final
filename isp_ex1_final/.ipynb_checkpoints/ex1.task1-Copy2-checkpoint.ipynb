{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed65d94-2713-4eb7-bd01-2efc7f7c3525",
   "metadata": {},
   "source": [
    "# MUST RENAME EVERYTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb56155-ef2e-49d8-a158-8dbb0e5dc86f",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "#### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1689add-2874-4d0e-ba48-d4c65b415757",
   "metadata": {},
   "source": [
    "#### installing OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1878e09-4834-45be-9bda-24ec3a913e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19202d99-bd43-4938-8ca7-72b817385ca4",
   "metadata": {},
   "source": [
    "#### importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfad02-d3cc-4b79-9372-787fcae6d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a1105-cc1d-471c-857c-e4ce1d43b5bd",
   "metadata": {},
   "source": [
    "#### loading the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2830e-b65c-492a-9238-e8130ea925f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading video\n",
    "# video_capture = cv2.VideoCapture('video/Traffic_Laramie_1.mp4')\n",
    "\n",
    "# # verify if opened succesfully\n",
    "# if not video_capture.isOpened():\n",
    "#     # print error message\n",
    "#     print(\"Sorry, video couldn't be open video.\")\n",
    "#     exit()\n",
    "# else:\n",
    "#     # print success message\n",
    "#     print(\"Video opened successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffc3b3-6d7d-41d3-b024-51fa47a6d457",
   "metadata": {},
   "source": [
    "# main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7805b5a1-4a48-4375-a203-ee34f7cb9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configuration\n",
    "# # Define region of interest points for the video frame\n",
    "# ROI_POINTS = np.array([[(0, 600), (0, 400), (400, 200), (600, 200), (800, 400), (800, 600)]], dtype=np.int32)\n",
    "# WIDTH_THRESHOLD = 80  # Width threshold for detecting cars based on contour width\n",
    "# HEIGHT_THRESHOLD = 50  # Height threshold for detecting cars based on contour height\n",
    "\n",
    "# def create_background_model():\n",
    "#     # Create a background subtractor using MOG2 method\n",
    "#     # Reference: https://docs.opencv.org/master/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\n",
    "#     return cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# def apply_morphology(mask):\n",
    "#     # Apply morphological transformations to improve the mask\n",
    "#     # Reference: https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html\n",
    "#     kernel = np.ones((3,3), np.uint8)\n",
    "#     mask = cv2.erode(mask, kernel, iterations=1)\n",
    "#     return cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "# def is_new_car(x, y, w, h, tracked_cars):\n",
    "#     \"\"\"\n",
    "#     Determines if a detected car is a new car or if it has been tracked before.\n",
    "\n",
    "#     Parameters:\n",
    "#     - x, y: Top-left coordinates of the detected car's bounding rectangle.\n",
    "#     - w, h: Width and height of the detected car's bounding rectangle.\n",
    "#     - tracked_cars: A list of lists containing previously tracked car positions.\n",
    "\n",
    "#     Returns:\n",
    "#     True if the car is new, False if it's a previously detected car.\n",
    "\n",
    "#     Logic:\n",
    "#     For every previously detected car, we check its last known position (which is stored at the end of its list of positions).\n",
    "#     If the current car's position is close enough (i.e., within the dimensions of its bounding rectangle) to the last known \n",
    "#     position of a previously detected car, we consider it to be the same car and update its tracked positions.\n",
    "#     Otherwise, it's treated as a new car.\n",
    "\n",
    "#     Reference:\n",
    "#     This approach is a basic form of object tracking. More advanced methods like SORT or DeepSORT can be used for more accurate tracking.\n",
    "#     Reference: https://arxiv.org/abs/1602.00763 (SORT: Simple Online and Realtime Tracking)\n",
    "#     \"\"\"\n",
    "\n",
    "#     for i, car in enumerate(tracked_cars):\n",
    "#         last_x, last_y = car[-1]  # Get the last known position of this car\n",
    "#         # Check if the current car's position is close to this car's position\n",
    "#         if abs(x - last_x) < w and abs(y - last_y) < h:\n",
    "#             tracked_cars[i].append((x, y))  # Update this car's positions\n",
    "#             return False  # It's not a new car\n",
    "#     # If no previously detected car is close enough, consider it a new car\n",
    "#     tracked_cars.append([(x, y)])\n",
    "#     return True\n",
    "\n",
    "# def detect_cars(frame, roi, backSub, tracked_cars):\n",
    "#     # Apply background subtraction to get foreground mask\n",
    "#     # Reference: https://docs.opencv.org/master/d0/d86/tutorial_py_image_arithmetics.html\n",
    "#     fgMask = backSub.apply(frame)\n",
    "#     fgMask = apply_morphology(fgMask)\n",
    "    \n",
    "#     # Use the defined ROI to focus on the region of interest in the frame\n",
    "#     mask = np.zeros_like(fgMask)\n",
    "#     cv2.fillPoly(mask, roi, 255)\n",
    "#     fgMask = cv2.bitwise_and(fgMask, mask)\n",
    "    \n",
    "#     # Find contours in the foreground mask\n",
    "#     # Reference: https://docs.opencv.org/master/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "#     contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     car_count = 0\n",
    "#     for contour in contours:\n",
    "#         # Use bounding rectangles to enclose detected cars\n",
    "#         # Reference: https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html\n",
    "#         x, y, w, h = cv2.boundingRect(contour)\n",
    "#         if w > WIDTH_THRESHOLD and h > HEIGHT_THRESHOLD:\n",
    "#             if is_new_car(x, y, w, h, tracked_cars):\n",
    "#                 car_count += 1\n",
    "#             cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "#     return frame, car_count\n",
    "\n",
    "# def main(video_capture):\n",
    "#     backSub = create_background_model()\n",
    "#     tracked_cars = deque(maxlen=5)  # Use a deque to store the position of cars with a fixed maximum length\n",
    "#     total_car_count = 0\n",
    "#     prev_count = 0\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = video_capture.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         frame, car_count = detect_cars(frame, ROI_POINTS, backSub, tracked_cars)\n",
    "#         total_car_count += car_count\n",
    "        \n",
    "#         elapsed_time = video_capture.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "#         # Display the video frame with detected cars\n",
    "#         # Reference: https://docs.opencv.org/master/dc/d43/tutorial_py_video_display.html\n",
    "#         if 60 < elapsed_time < 120:\n",
    "#             # This logic can be expanded or extracted to another function if more complexity is needed.\n",
    "#             prev_count = total_car_count\n",
    "#         elif elapsed_time >= 120:\n",
    "#             break\n",
    "\n",
    "#         # Display the video frame with detected cars\n",
    "#         cv2.imshow('frame', frame)\n",
    "#         if cv2.waitKey(1) == ord('q'):  # Exit loop on pressing 'q'\n",
    "#             break\n",
    "\n",
    "#     print(\"Detected cars on the Main Street: \", total_car_count)\n",
    "#     video_capture.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main(video_capture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b1bfc-049f-4259-b46e-c848ee7e0a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0604ec77-db2c-4f8b-b82d-1ec2782da377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5a118-5ace-425c-b5c4-7c7352e03d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Configuration\n",
    "VIDEO_PATH = 'video/Traffic_Laramie_1.mp4'\n",
    "# VIDEO_PATH = 'video/part1_2cars.mp4'\n",
    "\n",
    "ROI_POINTS = np.array([[(0, 600), (0, 400), (400, 200), (600, 200), (800, 400), (800, 600)]], dtype=np.int32)\n",
    "WIDTH_THRESHOLD = 80\n",
    "HEIGHT_THRESHOLD = 50\n",
    "\n",
    "def initialize_video(video_path):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Sorry, video couldn't be opened.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(\"Video opened successfully!\")\n",
    "    return video_capture\n",
    "\n",
    "def create_background_model():\n",
    "    return cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "def apply_morphology(mask):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "def is_new_car(x, y, w, h, tracked_cars):\n",
    "    for i, car in enumerate(tracked_cars):\n",
    "        last_x, last_y = car[-1]\n",
    "        if abs(x - last_x) < w and abs(y - last_y) < h:\n",
    "            tracked_cars[i].append((x, y))\n",
    "            return False\n",
    "    tracked_cars.append([(x, y)])\n",
    "    return True\n",
    "\n",
    "def apply_background_subtraction(frame, backSub):\n",
    "    fgMask = backSub.apply(frame)\n",
    "    return apply_morphology(fgMask)\n",
    "\n",
    "def apply_roi_mask(fgMask, roi):\n",
    "    mask = np.zeros_like(fgMask)\n",
    "    cv2.fillPoly(mask, roi, 255)\n",
    "    return cv2.bitwise_and(fgMask, mask)\n",
    "\n",
    "def find_contours(fgMask):\n",
    "    return cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "def process_contours(contours, tracked_cars, frame):\n",
    "    car_count = 0\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > WIDTH_THRESHOLD and h > HEIGHT_THRESHOLD:\n",
    "            if is_new_car(x, y, w, h, tracked_cars):\n",
    "                car_count += 1\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    return car_count\n",
    "\n",
    "\n",
    "def detect_cars(frame, roi, backSub, tracked_cars):\n",
    "    fgMask = apply_background_subtraction(frame, backSub)\n",
    "    fgMask = apply_roi_mask(fgMask, roi)\n",
    "    contours, _ = find_contours(fgMask)\n",
    "    car_count = process_contours(contours, tracked_cars, frame)\n",
    "    return frame, car_count\n",
    "\n",
    "def capture_frame(video_capture):\n",
    "    return video_capture.read()\n",
    "\n",
    "def handle_elapsed_time(video_capture):\n",
    "    elapsed_time = video_capture.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "    return elapsed_time >= 120\n",
    "\n",
    "def display_frame(frame):\n",
    "    cv2.imshow('frame', frame)\n",
    "    return cv2.waitKey(1) == ord('q')\n",
    "\n",
    "def summarize_detection(video_capture, total_car_count):\n",
    "    print(\"Detected cars on the Main Street:\", total_car_count)\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def initialize_detection():\n",
    "    backSub = create_background_model()\n",
    "    tracked_cars = deque(maxlen=5)\n",
    "    total_car_count = 0\n",
    "    return backSub, tracked_cars, total_car_count\n",
    "\n",
    "def detect_and_count_cars(frame, roi_points, backSub, tracked_cars):\n",
    "    frame, car_count = detect_cars(frame, roi_points, backSub, tracked_cars)\n",
    "    return frame, car_count\n",
    "\n",
    "def process_video(video_capture, roi_points, backSub, tracked_cars):\n",
    "    total_car_count = 0\n",
    "    while True:\n",
    "        ret, frame = capture_frame(video_capture)\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame, car_count = detect_and_count_cars(frame, roi_points, backSub, tracked_cars)\n",
    "        total_car_count += car_count\n",
    "        \n",
    "        if handle_elapsed_time(video_capture):\n",
    "            break\n",
    "\n",
    "        if display_frame(frame):\n",
    "            break\n",
    "            \n",
    "    return total_car_count\n",
    "\n",
    "def main(video_capture):\n",
    "    backSub, tracked_cars, total_car_count = initialize_detection()\n",
    "    total_car_count = process_video(video_capture, ROI_POINTS, backSub, tracked_cars)\n",
    "    summarize_detection(video_capture, total_car_count)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_capture = initialize_video(VIDEO_PATH)\n",
    "    main(video_capture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19766e-e15e-4dc1-8445-0d59f029e51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18986e-bd04-4414-b93e-69fdc1d36cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
