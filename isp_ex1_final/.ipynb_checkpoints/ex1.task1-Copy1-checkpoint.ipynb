{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed65d94-2713-4eb7-bd01-2efc7f7c3525",
   "metadata": {},
   "source": [
    "# MUST RENAME EVERYTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb56155-ef2e-49d8-a158-8dbb0e5dc86f",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "#### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1689add-2874-4d0e-ba48-d4c65b415757",
   "metadata": {},
   "source": [
    "#### installing OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1878e09-4834-45be-9bda-24ec3a913e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/tech/anaconda3/lib/python3.10/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/tech/anaconda3/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19202d99-bd43-4938-8ca7-72b817385ca4",
   "metadata": {},
   "source": [
    "#### importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bfad02-d3cc-4b79-9372-787fcae6d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a1105-cc1d-471c-857c-e4ce1d43b5bd",
   "metadata": {},
   "source": [
    "#### loading the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d2830e-b65c-492a-9238-e8130ea925f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully!\n"
     ]
    }
   ],
   "source": [
    "# loading video\n",
    "video_capture = cv2.VideoCapture('video/Traffic_Laramie_1.mp4')\n",
    "\n",
    "# verify if opened succesfully\n",
    "if not video_capture.isOpened():\n",
    "    # print error message\n",
    "    print(\"Sorry, video couldn't be open video.\")\n",
    "    exit()\n",
    "else:\n",
    "    # print success message\n",
    "    print(\"Video opened successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffc3b3-6d7d-41d3-b024-51fa47a6d457",
   "metadata": {},
   "source": [
    "# main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7805b5a1-4a48-4375-a203-ee34f7cb9ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected cars on the Main Street:  12\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "# Define region of interest points for the video frame\n",
    "ROI_POINTS = np.array([[(0, 600), (0, 400), (400, 200), (600, 200), (800, 400), (800, 600)]], dtype=np.int32)\n",
    "WIDTH_THRESHOLD = 80  # Width threshold for detecting cars based on contour width\n",
    "HEIGHT_THRESHOLD = 50  # Height threshold for detecting cars based on contour height\n",
    "\n",
    "def create_background_model():\n",
    "    # Create a background subtractor using MOG2 method\n",
    "    # Reference: https://docs.opencv.org/master/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\n",
    "    return cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "def apply_morphology(mask):\n",
    "    # Apply morphological transformations to improve the mask\n",
    "    # Reference: https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "def is_new_car(x, y, w, h, tracked_cars):\n",
    "    \"\"\"\n",
    "    Determines if a detected car is a new car or if it has been tracked before.\n",
    "\n",
    "    Parameters:\n",
    "    - x, y: Top-left coordinates of the detected car's bounding rectangle.\n",
    "    - w, h: Width and height of the detected car's bounding rectangle.\n",
    "    - tracked_cars: A list of lists containing previously tracked car positions.\n",
    "\n",
    "    Returns:\n",
    "    True if the car is new, False if it's a previously detected car.\n",
    "\n",
    "    Logic:\n",
    "    For every previously detected car, we check its last known position (which is stored at the end of its list of positions).\n",
    "    If the current car's position is close enough (i.e., within the dimensions of its bounding rectangle) to the last known \n",
    "    position of a previously detected car, we consider it to be the same car and update its tracked positions.\n",
    "    Otherwise, it's treated as a new car.\n",
    "\n",
    "    Reference:\n",
    "    This approach is a basic form of object tracking. More advanced methods like SORT or DeepSORT can be used for more accurate tracking.\n",
    "    Reference: https://arxiv.org/abs/1602.00763 (SORT: Simple Online and Realtime Tracking)\n",
    "    \"\"\"\n",
    "\n",
    "    for i, car in enumerate(tracked_cars):\n",
    "        last_x, last_y = car[-1]  # Get the last known position of this car\n",
    "        # Check if the current car's position is close to this car's position\n",
    "        if abs(x - last_x) < w and abs(y - last_y) < h:\n",
    "            tracked_cars[i].append((x, y))  # Update this car's positions\n",
    "            return False  # It's not a new car\n",
    "    # If no previously detected car is close enough, consider it a new car\n",
    "    tracked_cars.append([(x, y)])\n",
    "    return True\n",
    "\n",
    "def detect_cars(frame, roi, backSub, tracked_cars):\n",
    "    # Apply background subtraction to get foreground mask\n",
    "    # Reference: https://docs.opencv.org/master/d0/d86/tutorial_py_image_arithmetics.html\n",
    "    fgMask = backSub.apply(frame)\n",
    "    fgMask = apply_morphology(fgMask)\n",
    "    \n",
    "    # Use the defined ROI to focus on the region of interest in the frame\n",
    "    mask = np.zeros_like(fgMask)\n",
    "    cv2.fillPoly(mask, roi, 255)\n",
    "    fgMask = cv2.bitwise_and(fgMask, mask)\n",
    "    \n",
    "    # Find contours in the foreground mask\n",
    "    # Reference: https://docs.opencv.org/master/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    car_count = 0\n",
    "    for contour in contours:\n",
    "        # Use bounding rectangles to enclose detected cars\n",
    "        # Reference: https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > WIDTH_THRESHOLD and h > HEIGHT_THRESHOLD:\n",
    "            if is_new_car(x, y, w, h, tracked_cars):\n",
    "                car_count += 1\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    return frame, car_count\n",
    "\n",
    "def main(video_capture):\n",
    "    backSub = create_background_model()\n",
    "    tracked_cars = deque(maxlen=5)  # Use a deque to store the position of cars with a fixed maximum length\n",
    "    total_car_count = 0\n",
    "    prev_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame, car_count = detect_cars(frame, ROI_POINTS, backSub, tracked_cars)\n",
    "        total_car_count += car_count\n",
    "        \n",
    "        elapsed_time = video_capture.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "        # Display the video frame with detected cars\n",
    "        # Reference: https://docs.opencv.org/master/dc/d43/tutorial_py_video_display.html\n",
    "        if 60 < elapsed_time < 120:\n",
    "            # This logic can be expanded or extracted to another function if more complexity is needed.\n",
    "            prev_count = total_car_count\n",
    "        elif elapsed_time >= 120:\n",
    "            break\n",
    "\n",
    "        # Display the video frame with detected cars\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):  # Exit loop on pressing 'q'\n",
    "            break\n",
    "\n",
    "    print(\"Detected cars on the Main Street: \", total_car_count)\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(video_capture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b1bfc-049f-4259-b46e-c848ee7e0a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
