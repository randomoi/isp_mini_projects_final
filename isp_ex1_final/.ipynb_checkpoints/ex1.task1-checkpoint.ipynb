{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb56155-ef2e-49d8-a158-8dbb0e5dc86f",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Task 1 - Motion Detection Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf60d23-906a-42e4-a8e5-ce1b8e45109f",
   "metadata": {},
   "source": [
    "### Background Subtraction and Frame Differencing \n",
    "The application works with \"background subtraction\" to separate moving cars from the video's background. The \"setup_background_model\" uses the \"MOG2\" background subtractor (“Gaussian Mixture-based Background/Foreground segmentation algorithm” [1]), which is effective in analyzing videos with recurring movements, such as vehicle detection [2]. To detect movement, the algorithm continually updates a background model through comparing the current frame against the model. The differences observed in these frames reveal areas of motion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a073a46-1afe-4c06-a548-54d76d6a1052",
   "metadata": {},
   "source": [
    "### Application Analysis\n",
    "- Video: The “cv2.VideoCapture” loads “Traffic_Laramie_1.mp4”.\n",
    "- ROI: The “REGION_OF_INTEREST” are the sections that will be analyzed in the video.  This is to prevent the recognition of vehicles throughout the entire video.\n",
    "- Background Subtraction: MOG2 is used to separate moving cars from the background video (“foreground mask”) [3]. The \"morphological_transformation\" function improves vehicle detection by using “erode()” [4] to reduce noise and “dilate()” [5]  to smooth the edges.\n",
    "- Vehicle Recognition: The outlines obtained from the mask are assessed based on size parameters (width and height) to identify vehicles. The “is_new_vehicle” function is designed to count each vehicle only once.\n",
    "- Vehicle Display: Lastly, the recognized cars are displayed with green rectangles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2273eed0-63db-4070-bb8d-1d6e1578a23d",
   "metadata": {},
   "source": [
    "### References:\n",
    "- [1] \tdocs.opencv.org, \"cv::BackgroundSubtractorMOG2 Class Reference,\" 22 August 2023. [Online]. Available: https://docs.opencv.org/3.4/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html#details. [Accessed 22 August 2023].\n",
    "\n",
    "- [2] \tPrantik, \"Background Extraction from videos using Gaussian Mixture Models,\" 23 May 2020. [Online]. Available: https://medium.com/@prantiksen4/background-extraction-from-videos-using-gaussian-mixture-models-6e11d743f932. [Accessed August 2023]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1689add-2874-4d0e-ba48-d4c65b415757",
   "metadata": {},
   "source": [
    "#### Installing OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1878e09-4834-45be-9bda-24ec3a913e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/tech/anaconda3/lib/python3.10/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/tech/anaconda3/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19202d99-bd43-4938-8ca7-72b817385ca4",
   "metadata": {},
   "source": [
    "#### Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36bfad02-d3cc-4b79-9372-787fcae6d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321558c-1aad-4f29-b090-0c77d58af0b0",
   "metadata": {},
   "source": [
    "### Motion Detection Code\n",
    "My code is written with small descriptive functions that have limited purpose to follow separation of concerns principals. Markdown cells were used to explain what each function does and inline comments were used to add additional information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74ce30-debd-45e9-9723-153dd27f2f41",
   "metadata": {},
   "source": [
    "#### START - code was written based on module materials, independed research and documentation. Please see [Code References](#codereferences) section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9888122-bcc2-4f66-814d-4a607ec5bbfb",
   "metadata": {},
   "source": [
    "#### defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ffc67ea-c286-43f0-8272-63d88d2a51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  \n",
    "\n",
    "# # video path for analysis\n",
    "FILE_PATH = 'assets/Traffic_Laramie_1.mp4'\n",
    "\n",
    "# sets up region of interest (ROI) in a form of polygon \n",
    "# https://docs.opencv.org/4.x/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "REGION_OF_INTEREST = np.array([[(0, 600), (0, 400), (400, 200), (600, 200), (800, 400), (800, 600)]], dtype=np.int32)\n",
    "\n",
    "# width and height constraints for cars in video\n",
    "WIDTH_CONSTRAINT = 80\n",
    "HEIGHT_CONSTRAINT = 50\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e562a8e-4a31-48fe-a7be-87df5148341b",
   "metadata": {},
   "source": [
    "#### sets up video from path by using VideoCapture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8a3e992-0783-4774-9791-e0d8a345622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html\n",
    "def setup_video(file_path):\n",
    "    video_from_file = cv2.VideoCapture(file_path)\n",
    "    if not video_from_file.isOpened():\n",
    "        print(f\"Oh, no! Video {os.path.basename(file_path)} could not open. Please check if it exists in the path.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(f\"The video {os.path.basename(file_path)} was successfully opened!\")\n",
    "    return video_from_file\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd6c4a-3597-4006-9c6d-b610e9dbaf2a",
   "metadata": {},
   "source": [
    "#### sets up a background subtraction model using MOG2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa34f6bb-7060-4d57-834c-068ebc8d1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\n",
    "# https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html\n",
    "def setup_background_model():\n",
    "    return cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd07def-210e-4677-a3cb-b08760b1bcdb",
   "metadata": {},
   "source": [
    "#### applies morphological transformation to the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "303c64d3-433d-4ba6-a804-683cd8a4891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://www.geeksforgeeks.org/erosion-dilation-images-using-opencv-python/\n",
    "# https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html\n",
    "def morphological_transformation(mask):\n",
    "    kernel_matrix = np.ones((3,3), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel_matrix, iterations=1)\n",
    "    return cv2.dilate(mask, kernel_matrix, iterations=3)\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf40191-3384-468c-9f0a-84d49a7aee1b",
   "metadata": {},
   "source": [
    "#### determines whether a detected vehicle is new or already being tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69eb0dd4-fb32-49e5-a95d-db58248fe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://www.geeksforgeeks.org/opencv-python-program-vehicle-detection-video-frame/\n",
    "def is_new_vehicle(x, y, w, h, tracked_vehicles):\n",
    "    for i, vehicle in enumerate(tracked_vehicles):\n",
    "        last_x_coordinate, last_y_coordinate = vehicle[-1]\n",
    "        if abs(x - last_x_coordinate) < w and abs(y - last_y_coordinate) < h:\n",
    "            tracked_vehicles[i].append((x, y))\n",
    "            return False\n",
    "    tracked_vehicles.append([(x, y)])\n",
    "    return True\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e8786-1756-44bd-9083-f30d98596e44",
   "metadata": {},
   "source": [
    "#### adds background subtraction to frame and returns foreground mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4451dba3-b2a8-490c-8f34-bdf601ed6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d3/d89/tutorial_table_of_content_bgsegm.html\n",
    "# https://docs.opencv.org/4.x/d8/d38/tutorial_bgsegm_bg_subtraction.html\n",
    "# https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html\n",
    "def perform_background_subtraction(frame, background_subtraction):\n",
    "    foreground_mask = background_subtraction.apply(frame)\n",
    "    return morphological_transformation(foreground_mask)\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e52d7-357f-46e3-918a-a8cb8399db1c",
   "metadata": {},
   "source": [
    "#### applies region of interest mask to foreground mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1bdbb99-55c6-499e-9a6e-e680c7edb1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d3/dc1/tutorial_basic_linear_transform.html\n",
    "# https://stackoverflow.com/questions/71837896/how-to-mask-outside-or-inside-an-arbitrary-shape-in-python\n",
    "def apply_region_of_interest_mask(foreground_mask, region_of_interest):\n",
    "    mask = np.zeros_like(foreground_mask)\n",
    "    cv2.fillPoly(mask, region_of_interest, 255)\n",
    "    return cv2.bitwise_and(foreground_mask, mask)\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af33d0-819d-4a3c-b278-127df1e928c4",
   "metadata": {},
   "source": [
    "#### finds contours from foreground mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18c10739-02d7-4d5b-96cd-f4f3795e980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "# https://gist.github.com/pknowledge/8933224beea63ffd818f72da76b18f3e\n",
    "def detect_contours(foreground_mask):\n",
    "    return cv2.findContours(foreground_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079163a1-c43b-4d39-9b9b-5e12dfe253ed",
   "metadata": {},
   "source": [
    "#### analyzes detected contours and decides if they are new vehicle; draws rectangles around vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4cbf7567-4753-4695-9a24-0131871d392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n",
    "# https://stackoverflow.com/questions/71672549/cv2-boundingrect-creating-issue\n",
    "# https://www.tutorialspoint.com/how-to-find-the-bounding-rectangle-of-an-image-contour-in-opencv-python\n",
    "def analyze_contours(contours, tracked_vehicles, frame):\n",
    "    vehicle_count = 0\n",
    "    for contour in contours:\n",
    "        # bounding rectangle of contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # if more than constraints \n",
    "        if w > WIDTH_CONSTRAINT and h > HEIGHT_CONSTRAINT:\n",
    "            if is_new_vehicle(x, y, w, h, tracked_vehicles):\n",
    "                vehicle_count += 1\n",
    "            # draws a rectangle around detected vehicle\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    return vehicle_count\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad56df-dd01-4cba-b35a-c37d6dcc3cf6",
   "metadata": {},
   "source": [
    "#### detects vehicles in specified frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61eaad93-47c6-466a-8c94-66fd5471ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://www.geeksforgeeks.org/opencv-python-program-vehicle-detection-video-frame/\n",
    "def detect_vehicles(frame, region_of_interest, background_subtraction, tracked_vehicles):\n",
    "    # adds background subtraction to get foreground mask\n",
    "    foreground_mask = perform_background_subtraction(frame, background_subtraction)\n",
    "    # adds region of interest to mask\n",
    "    foreground_mask = apply_region_of_interest_mask(foreground_mask, region_of_interest)\n",
    "    # gets contours from mask\n",
    "    contours, _ = detect_contours(foreground_mask)\n",
    "    # checks contours to determine vehicle count \n",
    "    vehicle_count = analyze_contours(contours, tracked_vehicles, frame)\n",
    "    return frame, vehicle_count\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e25b31-b091-42be-a2fc-e9db12f0ef94",
   "metadata": {},
   "source": [
    "#### gets frame from video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "727ed9af-b1a2-4973-b18f-c4bd4b184294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html#adf291f3a44e1ec8a6fd74d5f8b47e444\n",
    "def get_frame(video_from_file):\n",
    "    return video_from_file.read()\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f8672-2594-4390-a33b-b87e735aceee",
   "metadata": {},
   "source": [
    "#### checks if elapsed time since begining of video is more than 120 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fee2776c-1c65-48b0-b3bb-e8e8451e901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html#a473055e77dd7faa4d26d686226b292c1\n",
    "# https://stackoverflow.com/questions/44759407/why-does-opencv-cap-getcv2-cap-prop-pos-msec-only-return-0\n",
    "def check_elapsed_time(video_from_file):\n",
    "    video_duration = video_from_file.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "    return video_duration >= 120\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b88f7d-a076-4fb9-b44c-9f3578a3a543",
   "metadata": {},
   "source": [
    "#### render frame and listen for 'q' key press to stop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16af95d1-fd23-4079-bccb-7d03bac6e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "\n",
    "# https://docs.opencv.org/4.x/d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7\n",
    "# https://stackoverflow.com/questions/44854699/why-does-the-cv2-imshow-does-not-render-without-cv2-waitkey\n",
    "def render_frame(frame):\n",
    "    cv2.imshow('frame', frame)\n",
    "    return cv2.waitKey(1) == ord('q')\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c4e81-78a3-48ab-afab-fb9d943ebce5",
   "metadata": {},
   "source": [
    "#### detection results to print count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "036649cd-c8de-4b67-9efa-b44c114d134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://www.geeksforgeeks.org/python-opencv-destroyallwindows-function/\n",
    "# https://stackoverflow.com/questions/76988645/opencv-video-capture-window-closes-after-a-second\n",
    "def detection_results(video_from_file, total_vehicle_count):\n",
    "    print(\"Total vehicles detected on Main Street:\", total_vehicle_count)\n",
    "    video_from_file.release()\n",
    "    # close all windows\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ccb4f7-d2d2-47b7-aa9e-179519e7ddbd",
   "metadata": {},
   "source": [
    "#### starts background model, vehicle tracking, and vehecle counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d76a0e94-a349-4807-9247-5577c10027d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://pythontic.com/containers/deque/introduction\n",
    "def start_detection():\n",
    "    # background subtraction model\n",
    "    background_subtraction = setup_background_model()\n",
    "    # start deque to track only last 5 vehicles\n",
    "    tracked_vehicles = deque(maxlen=5)\n",
    "    total_vehicle_count = 0\n",
    "    return background_subtraction, tracked_vehicles, total_vehicle_count\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a3d32-0f5a-4791-b042-c5b3f777ad0f",
   "metadata": {},
   "source": [
    "#### detects and counts vehicles in one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81fec0e5-1208-42c2-a64a-e892ae54dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html\n",
    "def detect_and_count_vehicles(frame, roi_area, background_subtraction, tracked_vehicles):\n",
    "    frame, vehicle_count = detect_vehicles(frame, roi_area, background_subtraction, tracked_vehicles)\n",
    "    return frame, vehicle_count\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8050b786-ddf7-42a6-bb9b-fa95d8fbbacb",
   "metadata": {},
   "source": [
    "#### analyzes full video, detects and counts vehicles in every frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc08b2de-7783-4e37-a321-21efd137a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "\n",
    "# https://www.vicomtech.org/upload/download/publicaciones/20111125_LuisUnzueta_AdaptiveM_article_42.pdf\n",
    "def analyze_video(video_from_file, roi_area, background_subtraction, tracked_vehicles):\n",
    "    total_vehicle_count = 0\n",
    "    while True:\n",
    "        frame_found, frame = get_frame(video_from_file)\n",
    "        # if frame not found, break out of loop\n",
    "        if not frame_found:\n",
    "            break\n",
    "\n",
    "        # detect + count vehicles in current frame\n",
    "        frame, vehicle_count = detect_and_count_vehicles(frame, roi_area, background_subtraction, tracked_vehicles)\n",
    "        total_vehicle_count += vehicle_count\n",
    "\n",
    "        # if video duration is more than 120 secs, break out of loop\n",
    "        if check_elapsed_time(video_from_file):\n",
    "            break\n",
    "\n",
    "        # render frame and break loop if 'q' is selected\n",
    "        if render_frame(frame):\n",
    "            break\n",
    "            \n",
    "    return total_vehicle_count\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121110d-ffb7-4dc1-a470-3faec66009c1",
   "metadata": {},
   "source": [
    "#### initializes video analyses and vehicle count results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e19766e-e15e-4dc1-8445-0d59f029e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video Traffic_Laramie_1.mp4 was successfully opened!\n",
      "Total vehicles detected on Main Street: 12\n",
      "Video window closed.\n"
     ]
    }
   ],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://stackoverflow.com/questions/25182278/opencv-python-video-playback-how-to-set-the-right-delay-for-cv2-waitkey\n",
    "# https://github.com/opencv/opencv/issues/7343\n",
    "def main(video_from_file):\n",
    "        # initialize background_subtraction, tracked_vehicles, total_vehicle_count\n",
    "        background_subtraction, tracked_vehicles, total_vehicle_count = start_detection()\n",
    "        # analyze video to detect and count vehicles\n",
    "        total_vehicle_count = analyze_video(video_from_file, REGION_OF_INTEREST, background_subtraction, tracked_vehicles)\n",
    "        # detection results\n",
    "        detection_results(video_from_file, total_vehicle_count)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # initialize video from file\n",
    "    video_from_file = setup_video(FILE_PATH)\n",
    "    \n",
    "    try:\n",
    "        # initialize main function\n",
    "        main(video_from_file)\n",
    "\n",
    "    finally:\n",
    "        print(\"Video window closed.\")\n",
    "        video_from_file.release()\n",
    "        cv2.waitKey(1)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d853885-8e98-49d0-99d9-e9bf64da3b09",
   "metadata": {},
   "source": [
    "#### END - code was written based on module materials, independed research and documentation. Please see [Code References](#codereferences) section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdc90e-8a66-45bb-98e4-d0cfefaf52dd",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b712f-3d41-4770-b99c-dd18f755a9cd",
   "metadata": {},
   "source": [
    "<a id='codereferences'></a>\n",
    "## Code References\n",
    "\n",
    "- https://docs.opencv.org/4.x/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "- https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html\n",
    "- https://docs.opencv.org/4.x/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\n",
    "- https://www.geeksforgeeks.org/erosion-dilation-images-using-opencv-python/\n",
    "- https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html\n",
    "- https://docs.opencv.org/4.x/d3/d89/tutorial_table_of_content_bgsegm.html\n",
    "- https://docs.opencv.org/4.x/d8/d38/tutorial_bgsegm_bg_subtraction.html\n",
    "- https://docs.opencv.org/4.x/d3/dc1/tutorial_basic_linear_transform.html\n",
    "- https://docs.opencv.org/4.x/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "- https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html#adf291f3a44e1ec8a6fd74d5f8b47e444\n",
    "- https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html#a473055e77dd7faa4d26d686226b292c1\n",
    "- https://docs.opencv.org/4.x/d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7\n",
    "- https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html\n",
    "- https://stackoverflow.com/questions/71837896/how-to-mask-outside-or-inside-an-arbitrary-shape-in-python\n",
    "- https://gist.github.com/pknowledge/8933224beea63ffd818f72da76b18f3e\n",
    "- https://omes-va.com/operadores-bitwise/\n",
    "- https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html\n",
    "- https://stackoverflow.com/questions/71672549/cv2-boundingrect-creating-issue\n",
    "- https://www.tutorialspoint.com/how-to-find-the-bounding-rectangle-of-an-image-contour-in-opencv-python\n",
    "- https://learnopencv.com/background-subtraction-with-opencv-and-bgs-libraries/\n",
    "- http://www-vpu.eps.uam.es/webvpu/media/docs/publicacion/ArticuloCongreso/2010September_ICIP%202010_stationaryForegroundDetectionUsingBackgroundSubtractionAndTemporalDifferenceInVideoSurveillance.pdf\n",
    "- https://stackoverflow.com/questions/44759407/why-does-opencv-cap-getcv2-cap-prop-pos-msec-only-return-0\n",
    "- https://stackoverflow.com/questions/44854699/why-does-the-cv2-imshow-does-not-render-without-cv2-waitkey\n",
    "- https://github.com/opencv/opencv-python/issues/690\n",
    "- https://stackoverflow.com/questions/63932668/set-an-roi-in-opencv\n",
    "- https://github.com/HoangPhungz25/Vehicle-counting\n",
    "- https://www.vicomtech.org/upload/download/publicaciones/20111125_LuisUnzueta_AdaptiveM_article_42.pdf\n",
    "- https://www.geeksforgeeks.org/python-opencv-destroyallwindows-function/\n",
    "- https://stackoverflow.com/questions/76988645/opencv-video-capture-window-closes-after-a-second\n",
    "- https://www.geeksforgeeks.org/opencv-python-program-vehicle-detection-video-frame/\n",
    "- https://pythontic.com/containers/deque/introduction\n",
    "- https://stackoverflow.com/questions/25182278/opencv-python-video-playback-how-to-set-the-right-delay-for-cv2-waitkey\n",
    "- https://github.com/opencv/opencv/issues/7343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0ff1e-b3a8-4168-8ec2-3d07281d7c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
