{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb56155-ef2e-49d8-a158-8dbb0e5dc86f",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Task 2 - Motion Detection and Counting Cars \n",
    "\n",
    "The program will detect **6** vehicles in ***\"Traffic_Laramie_1.mp4\"*** and **4** vehicles in ***\"Traffic_Laramie_2.mp4\"*** going from the city’s downtown to the city centre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1689add-2874-4d0e-ba48-d4c65b415757",
   "metadata": {},
   "source": [
    "#### installing OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1878e09-4834-45be-9bda-24ec3a913e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/tech/anaconda3/lib/python3.10/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/tech/anaconda3/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: numpy in /Users/tech/anaconda3/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: tabulate in /Users/tech/anaconda3/lib/python3.10/site-packages (0.8.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19202d99-bd43-4938-8ca7-72b817385ca4",
   "metadata": {},
   "source": [
    "#### importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bfad02-d3cc-4b79-9372-787fcae6d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffc3b3-6d7d-41d3-b024-51fa47a6d457",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Motion Detection Code for Two Videos\n",
    "My code is written with small descriptive functions that have limited purpose to follow separation of concerns principals. Markdown cells were used to explain what each function does and inline comments were used to add additional information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f899884-830c-401d-9a04-849fe5a0354d",
   "metadata": {},
   "source": [
    "#### START - code was written based on module materials, independed research and documentation. Please see [Code References](#codereferences) section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf78c3d-7c9d-43c7-aca4-410513e56835",
   "metadata": {},
   "source": [
    "#### sets up video from path by using VideoCapture, and sets up background subtraction using MOG2 and warm up with first 50 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2bdcb9-d06b-4249-9519-d89a68ec168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/master/de/de1/group__video__motion.html\n",
    "def setup_video(file_path):   \n",
    "    print(f\"Evaluating video: {os.path.basename(file_path)}\")\n",
    "\n",
    "    # setting up video with helper function get_video which gets video by using cv2.videoCapture\n",
    "    video_from_file = get_video(file_path)\n",
    "    if not video_from_file.isOpened():\n",
    "        print(f\"Oh, no! Video {os.path.basename(file_path)} could not open. Please check if it exists in the path.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(f\"The video {os.path.basename(file_path)} was successfully opened!\")\n",
    "    \n",
    "    background_subtraction = setup_background_model()\n",
    "    \n",
    "     # warm up phase with first 50 frames for background subtraction stabilization\n",
    "     # https://github.com/shrutitharmia/motion-detector\n",
    "     # https://github.com/shrutitharmia/motion-detector/blob/main/motion_detector.py\n",
    "    warm_up_frames = 50\n",
    "    for _ in range(warm_up_frames):\n",
    "        frame_found, frame = video_from_file.read()\n",
    "        if not frame_found:\n",
    "            return None, None\n",
    "        background_subtraction.apply(frame)\n",
    "    \n",
    "    return video_from_file, background_subtraction\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409acc6-2509-486c-98f7-a2d1d3f11bfd",
   "metadata": {},
   "source": [
    "#### sets up a background subtraction model using MOG2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dd3a4f-a29f-471d-9540-91c3229656a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\n",
    "# https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html\n",
    "# https://docs.opencv.org/4.x/de/de1/group__video__motion.html\n",
    "# https://answers.opencv.org/question/182167/what-does-the-history-of-this-function-createbackgroundsubtractormog2-means/\n",
    "def setup_background_model():\n",
    "    return cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468c2c2-605a-441c-a740-23d9575733ca",
   "metadata": {},
   "source": [
    "#### gets video from path path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8a64bd-7d67-4dd3-b5f2-43fcf8717b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://note.nkmk.me/en/python-opencv-videocapture-file-camera/\n",
    "# https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html\n",
    "def get_video(file_path):\n",
    "    return cv2.VideoCapture(file_path)\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f14242-8118-4d64-8808-40d2407f77da",
   "metadata": {},
   "source": [
    "#### calculates duration of video in secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e3957b-e0cf-4c7d-8311-84d5dc379713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://www.tutorialspoint.com/get-video-duration-using-opencv-python\n",
    "# https://stackoverflow.com/questions/31472155/python-opencv-cv2-cv-cv-cap-prop-frame-count-get-wrong-numbers\n",
    "# https://github.com/opencv/opencv/issues/24000\n",
    "def calculate_duration_in_seconds(video_from_file):\n",
    "    frames_per_seconds = video_from_file.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = video_from_file.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    video_duration_in_seconds = total_frames / frames_per_seconds\n",
    "    return video_duration_in_seconds\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f55db1-0ada-4638-b8f5-f32f80333fb4",
   "metadata": {},
   "source": [
    "#### obtains center of the vehicle’s bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d132e20-2282-41b3-9497-b0504198a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://github.com/ultralytics/ultralytics/issues/4212\n",
    "# http://www.open3d.org/docs/release/python_api/open3d.geometry.OrientedBoundingBox.html\n",
    "# https://imgaug.readthedocs.io/en/latest/_modules/imgaug/augmentables/bbs.html\n",
    "# https://github.com/carla-simulator/carla/blob/master/PythonAPI/examples/client_bounding_boxes.py\n",
    "# https://github.com/ultralytics/ultralytics/issues/2843\n",
    "class Vehicle:\n",
    "    def __init__(self, bounding_box):\n",
    "        self.bounding_box = bounding_box\n",
    "        self.since_last_update_frames = 0\n",
    "\n",
    "    # calculates center of bounding box      \n",
    "    def get_center(self):\n",
    "        x, y, w, h = self.bounding_box\n",
    "        return x + w // 2, y + h // 2 # enter of bounding box\n",
    "    \n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853da265-7cbc-4d44-9363-1c6c0af1b1f8",
   "metadata": {},
   "source": [
    "#### applies morphological transformation to mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb7e202-1338-415a-b179-7cdcdf587363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html\n",
    "# https://www.geeksforgeeks.org/python-opencv-morphological-operations/\n",
    "# https://medium.datadriveninvestor.com/image-processing-using-python-open-cv-part-2-72f2b75918e7\n",
    "# https://stackoverflow.com/questions/55288523/im-getting-error-with-morphological-mask\n",
    "def morphological_transformation(foreground_mask):\n",
    "    # processes mask by enhancing region of interest\n",
    "    kernel_matrix = np.ones((5, 5), np.uint8)\n",
    "    foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, kernel_matrix)\n",
    "    mask = np.zeros_like(foreground_mask)\n",
    "    REGION_OF_INTEREST = np.array([[(300, 500), (350, 350), (400, 100), (400, 100), (400, 200), (500, 300)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, REGION_OF_INTEREST, 255)\n",
    "    foreground_mask = cv2.bitwise_and(foreground_mask, mask)\n",
    "    \n",
    "    return foreground_mask # enhanced mask\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e09be6-0614-4164-a15b-1ea67624f62b",
   "metadata": {},
   "source": [
    "#### render one frame of video at the time and listen for 'q' key press to stop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22add55-7ed1-4d55-b29c-1b179ab27d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://forum.opencv.org/t/how-to-use-waitkey-with-videocapture/10718\n",
    "# https://answers.opencv.org/question/232169/closing-video-with-any-key/\n",
    "# https://www.geeksforgeeks.org/python-opencv-waitkey-function/\n",
    "def render_frame(frame):\n",
    "    # renders one frame at the time and listen for 'q' key press to stop it\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(30) == ord('q'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a9e98-2289-47d4-ba16-72f84b8396c8",
   "metadata": {},
   "source": [
    "#### analyzes each frame of video, tracks and detects vehicles to return all detected vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c6545d-e6b1-4b23-8759-c46a0f5579a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://stackoverflow.com/questions/26344036/python-opencv-background-subtraction\n",
    "# https://www.geeksforgeeks.org/python-opencv-background-subtraction/\n",
    "def analyze_frames(video_from_file, background_subtraction):\n",
    "    tracked_vehicles = []\n",
    "    all_detected_vehicles = []\n",
    "\n",
    "    while True:\n",
    "        frame_found, frame = video_from_file.read()\n",
    "        if not frame_found:\n",
    "            break\n",
    "\n",
    "        foreground_mask = background_subtraction.apply(frame)\n",
    "        foreground_mask = morphological_transformation(foreground_mask)\n",
    "\n",
    "        tracked_vehicles, all_detected_vehicles = detect_track_vehicles_in_current_frame(foreground_mask, tracked_vehicles, all_detected_vehicles, frame)\n",
    "\n",
    "        if render_frame(frame):\n",
    "            break\n",
    "\n",
    "    return all_detected_vehicles\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d7b9b-6dde-4f86-8638-ef24432b8085",
   "metadata": {},
   "source": [
    "#### analyzes one video, detects and tracks vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1610c3c7-646d-4bad-8832-ff1eb91d31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://cs.gmu.edu/~kosecka/cs482/code-examples/opencv-python/OpenCV_Python.pdf\n",
    "# https://analyticsindiamag.com/getting-started-with-opencv-in-python/\n",
    "# https://www.javatpoint.com/opencv-videocapture\n",
    "# https://stackoverflow.com/questions/54794177/cv2-error-opencv3-4-3-error-after-finish-playing-video\n",
    "def analyze_video(file_path):\n",
    "    video_from_file, background_subtraction = setup_video(file_path)\n",
    "    if video_from_file is None or background_subtraction is None:\n",
    "        return\n",
    "\n",
    "    all_detected_vehicles = analyze_frames(video_from_file, background_subtraction)\n",
    "    \n",
    "    unique_vehicle_count = len(all_detected_vehicles)\n",
    "    video_duration_in_seconds = calculate_duration_in_seconds(video_from_file)\n",
    "    vehicles_per_second = unique_vehicle_count / video_duration_in_seconds\n",
    "    vehicles_per_minute = vehicles_per_second * 60\n",
    "    \n",
    "    video_from_file.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # return dict with video results\n",
    "    return {\n",
    "        \"Video name\": os.path.basename(file_path),\n",
    "        \"Total number of cars\": unique_vehicle_count,\n",
    "        \"Cars per minute\": vehicles_per_minute\n",
    "    } \n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d0754-fe30-47ae-971f-1bcb0550ac39",
   "metadata": {},
   "source": [
    "#### detects vehicles in frame by using contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b07e9ee-fa2c-4bcc-9e6e-3d28d43bcff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html\n",
    "# https://learnopencv.com/contour-detection-using-opencv-python-c/\n",
    "# https://gist.github.com/m3hrdadfi/664de37b216eb5c97affb4b3db331089\n",
    "# https://stackoverflow.com/questions/68399140/python-cv2-find-contours\n",
    "def detect_vehicles(foreground_mask):\n",
    "    contours, _ = cv2.findContours(foreground_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detected_vehicles = []\n",
    "    WIDTH_CONSTRAINT = 100\n",
    "    HEIGHT_CONSTRAINT = 45\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > WIDTH_CONSTRAINT and h > HEIGHT_CONSTRAINT:\n",
    "            detected_vehicles.append((x, y, w, h))\n",
    "    return detected_vehicles # returns boundting boxes which are identified vehicles\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8c393-5109-4427-844f-ec5bafa4a408",
   "metadata": {},
   "source": [
    "#### matchs detected vehicles with presently tracked vehicles and handle mismatched vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc44139a-44ea-4577-982f-3313162cd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://thepythoncode.com/article/real-time-vehicle-tracking-and-counting-with-yolov8-opencv#google_vignette\n",
    "# https://github.com/yehengchen/Object-Detection-and-Tracking/blob/master/OneStage/yolo/yolov3_sort/main.py\n",
    "# https://carla.readthedocs.io/en/latest/tuto_G_bounding_boxes/\n",
    "# https://github.com/jeongwhanchoi/object-detection\n",
    "# https://github.com/pytorch/vision/issues/2740\n",
    "# https://www.mdpi.com/1424-8220/19/19/4263\n",
    "def track_and_match(detected_vehicles, tracked_vehicles, all_detected_vehicles):\n",
    "    # array of current vehicles\n",
    "    current_vehicles = []\n",
    "    # loops over bounding boxes of detected vehicles \n",
    "    for x, y, w, h in detected_vehicles:\n",
    "        # calcutes center of bounding box of vehicle\n",
    "        vehicle_center = (x + w // 2, y + h // 2)\n",
    "        match_found = False # flag\n",
    "        # loops over each tracked vehicles \n",
    "        for vehicle in tracked_vehicles:\n",
    "            # calculates distance between center of tracked vehicle and center of detected vehicle\n",
    "            distance = np.linalg.norm(np.array(vehicle.get_center()) - np.array(vehicle_center))\n",
    "            # if less than max width and height, than it's a match\n",
    "            if distance < max(w, h):  # max of width and height as constraint\n",
    "                # tracked vehicle's bounding box is updated to match detected's bounding box\n",
    "                vehicle.bounding_box = (x, y, w, h)\n",
    "                # resets frame counter \n",
    "                vehicle.since_last_update_frames = 0\n",
    "                match_found = True # flag that vehicle was found\n",
    "                break\n",
    "        # if not match, then identified vehicle is a new vehicle\n",
    "        if not match_found:\n",
    "            new_vehicle = Vehicle((x, y, w, h)) # new vehicle\n",
    "            current_vehicles.append(new_vehicle) # adds it to the list of current vehicles\n",
    "            all_detected_vehicles.append(new_vehicle) # adds it to list of all vehicles\n",
    "    return current_vehicles, all_detected_vehicles\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990efe00-1dd7-482d-9b1d-1279f8583b7b",
   "metadata": {},
   "source": [
    "#### draws rects around detected vehicle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b01b83e-0942-44b7-b7bc-1dab807ae08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://www.geeksforgeeks.org/python-opencv-cv2-rectangle-method/\n",
    "def draw_detected_vehicles_rectangles(frame, detected_vehicles):\n",
    "    for x, y, w, h in detected_vehicles:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f17115-4e75-46dd-91c2-775b10550568",
   "metadata": {},
   "source": [
    "#### updates frames since last counter for all tracked vehicles and removes them if no longer in frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c35c7c-a5f3-4561-a52e-e957af49b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.python.org/3/library/copy.html\n",
    "def update_and_remove_vehicles(tracked_vehicles):\n",
    "    # loop over a copy of tracked vehicle list \n",
    "    for vehicle in tracked_vehicles.copy():\n",
    "        # increment counter indicating how many frames it has been since the car was last updated\n",
    "        vehicle.since_last_update_frames += 1\n",
    "        # if vehicle not updated in over 30 frames, remove it from tracked vehicles\n",
    "        if vehicle.since_last_update_frames > 30:\n",
    "            tracked_vehicles.remove(vehicle)\n",
    "            \n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf4a6a-c4f8-4346-91a7-ac38a232c14d",
   "metadata": {},
   "source": [
    "#### detects and track vehicles in current frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbcda082-6d3a-42da-844e-edfb6232c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://www.programiz.com/python-programming/methods/list/extend\n",
    "def detect_track_vehicles_in_current_frame(foreground_mask, tracked_vehicles, all_detected_vehicles, frame):\n",
    "    # detects vehicles with foreground mask\n",
    "    detected_vehicles = detect_vehicles(foreground_mask)\n",
    "    # matchsand unmatches detected with tracked vehicles\n",
    "    current_vehicles, all_detected_vehicles = track_and_match(detected_vehicles, tracked_vehicles, all_detected_vehicles)\n",
    "    # draws rects for detected vehicles\n",
    "    draw_detected_vehicles_rectangles(frame, detected_vehicles)\n",
    "    # uses extend() to combine tracked vehicles list with new detected vehicles \n",
    "    tracked_vehicles.extend(current_vehicles)\n",
    "    # updates and remove vehicles not seen for specified time  \n",
    "    update_and_remove_vehicles(tracked_vehicles)\n",
    "    # returns new list of tracked and detected vehicles\n",
    "    return tracked_vehicles, all_detected_vehicles\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee21eb-e51e-4011-ab9d-0ec9997f1acb",
   "metadata": {},
   "source": [
    "####  analyzes videos in specified path, every video gets analyzed for with logic in analyze_video() function which detects and tracks vehicles to return a list of results for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec5d444a-3ef0-4aee-834b-4f5cb0d98467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://docs.python.org/3/library/os.path.html\n",
    "def analyze_videos(file_paths):\n",
    "    result_data_list = []\n",
    "    # individual videos\n",
    "    for file_path in file_paths:\n",
    "        result = analyze_video(file_path)\n",
    "        \n",
    "        # adds video name to result\n",
    "        if result is not None:  # make sure None results are not added\n",
    "            result['Video name'] = os.path.basename(file_path)\n",
    "            result_data_list.append(result)\n",
    "    return result_data_list\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09bcb76-a3b3-47a9-909a-eb8eb1ebfc0f",
   "metadata": {},
   "source": [
    "#### handles display of data in a table by using tabulate, df and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02c8a48-5949-4612-9e74-78d91869b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html\n",
    "# https://stackoverflow.com/questions/18528533/pretty-printing-a-pandas-dataframe\n",
    "def display_result_table(result_data_list):\n",
    "    df = pd.DataFrame(result_data_list)\n",
    "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5abbbf-7aa6-487c-afc2-62481fd0d6bf",
   "metadata": {},
   "source": [
    "#### calls analyze_videos and display_result_table functions which handle vehicle detection and tracking for indicated video paths and displaying results in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca06742-9714-4bed-b28f-2fca8da21c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating video: Traffic_Laramie_1.mp4\n",
      "The video Traffic_Laramie_1.mp4 was successfully opened!\n",
      "Evaluating video: Traffic_Laramie_2.mp4\n",
      "The video Traffic_Laramie_2.mp4 was successfully opened!\n",
      "+-----------------------+------------------------+-------------------+\n",
      "| Video name            |   Total number of cars |   Cars per minute |\n",
      "+=======================+========================+===================+\n",
      "| Traffic_Laramie_1.mp4 |                      6 |           2.02338 |\n",
      "+-----------------------+------------------------+-------------------+\n",
      "| Traffic_Laramie_2.mp4 |                      4 |           2.27101 |\n",
      "+-----------------------+------------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# START - code was written based on module materials, independed research and documentation. Please see Code References section for all links. \n",
    "\n",
    "def main():\n",
    "        file_paths = ['assets/Traffic_Laramie_1.mp4', 'assets/Traffic_Laramie_2.mp4']\n",
    "        result_data_list = analyze_videos(file_paths)\n",
    "        display_result_table(result_data_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# END - code was written based on module materials, independed research and documentation. Please see Code References section for all links. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94491d-cca1-432a-ad40-c9a986e1a82a",
   "metadata": {},
   "source": [
    "#### END - code was written based on module materials, independed research and documentation. Please see [Code References](#codereferences) section for all links.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaaf6f1-24d5-4a8f-a9dc-1916122b7f3e",
   "metadata": {},
   "source": [
    "<a id='codereferences'></a>\n",
    "## Code References\n",
    "- https://docs.opencv.org/master/de/de1/group__video__motion.html\n",
    "- https://github.com/shrutitharmia/motion-detector\n",
    "- https://github.com/shrutitharmia/motion-detector/blob/main/motion_detector.py\n",
    "- https://docs.opencv.org/4.x/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html\n",
    "- https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html\n",
    "- https://docs.opencv.org/4.x/de/de1/group__video__motion.html\n",
    "- https://answers.opencv.org/question/182167/what-does-the-history-of-this-function-createbackgroundsubtractormog2-means/\n",
    "- https://note.nkmk.me/en/python-opencv-videocapture-file-camera/\n",
    "- https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html\n",
    "- https://www.tutorialspoint.com/get-video-duration-using-opencv-python\n",
    "- https://stackoverflow.com/questions/31472155/python-opencv-cv2-cv-cv-cap-prop-frame-count-get-wrong-numbers\n",
    "- https://github.com/opencv/opencv/issues/24000\n",
    "- https://github.com/ultralytics/ultralytics/issues/4212\n",
    "- http://www.open3d.org/docs/release/python_api/open3d.geometry.OrientedBoundingBox.html\n",
    "- https://imgaug.readthedocs.io/en/latest/_modules/imgaug/augmentables/bbs.html\n",
    "- https://github.com/carla-simulator/carla/blob/master/PythonAPI/examples/client_bounding_boxes.py\n",
    "- https://github.com/ultralytics/ultralytics/issues/2843\n",
    "- https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html\n",
    "- https://www.geeksforgeeks.org/python-opencv-morphological-operations/\n",
    "- https://medium.datadriveninvestor.com/image-processing-using-python-open-cv-part-2-72f2b75918e7\n",
    "- https://stackoverflow.com/questions/55288523/im-getting-error-with-morphological-mask\n",
    "- https://forum.opencv.org/t/how-to-use-waitkey-with-videocapture/10718\n",
    "- https://answers.opencv.org/question/232169/closing-video-with-any-key/\n",
    "- https://www.geeksforgeeks.org/python-opencv-waitkey-function/\n",
    "- https://stackoverflow.com/questions/26344036/python-opencv-background-subtraction\n",
    "- https://www.geeksforgeeks.org/python-opencv-background-subtraction/\n",
    "- https://cs.gmu.edu/~kosecka/cs482/code-examples/opencv-python/OpenCV_Python.pdf\n",
    "- https://analyticsindiamag.com/getting-started-with-opencv-in-python/\n",
    "- https://www.javatpoint.com/opencv-videocapture\n",
    "- https://stackoverflow.com/questions/54794177/cv2-error-opencv3-4-3-error-after-finish-playing-video\n",
    "- https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html\n",
    "- https://learnopencv.com/contour-detection-using-opencv-python-c/\n",
    "- https://gist.github.com/m3hrdadfi/664de37b216eb5c97affb4b3db331089\n",
    "- https://stackoverflow.com/questions/68399140/python-cv2-find-contours\n",
    "- https://thepythoncode.com/article/real-time-vehicle-tracking-and-counting-with-yolov8-opencv#google_vignette\n",
    "- https://github.com/yehengchen/Object-Detection-and-Tracking/blob/master/OneStage/yolo/yolov3_sort/main.py\n",
    "- https://carla.readthedocs.io/en/latest/tuto_G_bounding_boxes/\n",
    "- https://github.com/jeongwhanchoi/object-detection\n",
    "- https://github.com/pytorch/vision/issues/2740\n",
    "- https://www.mdpi.com/1424-8220/19/19/4263\n",
    "- https://www.geeksforgeeks.org/python-opencv-cv2-rectangle-method/\n",
    "- https://docs.python.org/3/library/copy.html\n",
    "- https://www.programiz.com/python-programming/methods/list/extend\n",
    "- https://docs.python.org/3/library/os.path.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html\n",
    "- https://stackoverflow.com/questions/18528533/pretty-printing-a-pandas-dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab242e5-84f5-44a7-94e1-98b3d3a690ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
